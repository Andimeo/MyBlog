title: 几种教科书里没有的排序
date: 2015-05-03 22:04:56
categories: 算法
tags:
- 排序
- 算法
- Lucene
---
今天开始看Lucene的源码了，从core模块的util开始看起。发现其中有几个排序的方法名字都没有听过，比如introsort、timsort。结合lucene的代码，又在网上进行了相关知识的搜索，发现在比较新的语言中，比如Java 7和python中，默认的排序算法已经不是教科书中的quicksort了。今天就记录一下新学到的这三个算法。

<!-- more -->

##Inplace Merge Sort
还记得年初去Google面试的时候，一个北欧的面试官问过我，为什么大部分库函数实现排序时都选择了quicksort，而不是mergesort。当时临场反应，给出了面试官想要的答案，即quicksort可以in place执行，而mergesort需要额外的空间。可是今天看Lucene的代码时，在org.apache.lucene.util.Sorter中，看到了一个函数名叫mergeInPlace。难道被Google的面试官骗了，话说我面试别人的时候，还出过这道题。好的，看看Lucene是怎么做到in place的吧。

```
void mergeInPlace(int from, int mid, int to) {
    if (from == mid || mid == to || compare(mid - 1, mid) <= 0) {
      return;
    } else if (to - from == 2) {
      swap(mid - 1, mid);
      return;
    }
    //1. from ... from' ... mid ... to ... to'
    //Suppose [from, mid) and [mid, to) are two sorted segments. 
    //Obviously, after the two loops below, numbers in [from, from') are smaller than others,
    //numbers in [to, to') are greater than others. So we only need to focus on [from', to')
    while (compare(from, mid) <= 0) {
      ++from;
    }
    while (compare(mid - 1, to - 1) <= 0) {
      --to;
    }
    //2. Take the middle element of [from', mid) as a pivot named first_cut,
    //then find the lower_bound of it in [mid, to'), named second_cut    
    int first_cut, second_cut;
    int len11, len22;
    if (mid - from > to - mid) {
      len11 = (mid - from) >>> 1;
      first_cut = from + len11;
      second_cut = lower(mid, to, first_cut); //lower_bound
      len22 = second_cut - mid;
    } else {
      len22 = (to - mid) >>> 1;
      second_cut = mid + len22;
      first_cut = upper(from, mid, second_cut); //upper_bound
      len11 = first_cut - from;
    }
    //3. We can tell that [from', first_cut), [mid, second_cut) are smaller than [first_cut],
    //while [first_cut, mid) and [second_cut, to') are greater than or equal to [first_cut].
    //Of course, [from, from') are also smaller than [first_cut], the same to [to', to].
    //So actually we partition the sequence into two parts, one is greater than the pivot,
    //while the other one is smaller than the pivot. (Similar as the partition phase of quicksort)
    rotate(first_cut, mid, second_cut); //reverse [first_cut, mid), [mid, second_cut), [first_cut, second_cut) respectively
    final int new_mid = first_cut + len22;
    mergeInPlace(from, first_cut, new_mid);
    mergeInPlace(new_mid, second_cut, to);
  }
```

这段代码中用到了三个辅助函数，分别是lower、upper和rotate。lower和upper分别代表lower_boudn和upper_bound的意思，这里顺别复习了一下lower_bound和upper_bound的意义。lower_bound(l, r, val)是指[l, r)中大于等于val的第一个元素，而upper_bound(l, r, val)则指[l, r)中大于val的第一个元素。而rotate(l, m, r)则是分别反转[l, m), [m, r)和[l, r)三个区间各一次，典型的应用就是反转一个句子中的单词。

仔细品味这里用的lower_bound和upper_bound，可以发现这个merge过程是stable的，所以这种排序也就是一种稳定排序。

结合我在代码中穿插的注释，第一段代码，算是一个简单的优化，排除了一些已经就位的元素，接下来只需要对剩下的元素进行merge即可。

第二段代码，则将[from', mid)的中点作为一个pivot，然后再[mid, to')中寻找pivot的lower_bound，这样就将整个区间分为了四个部分。结合第三段代码，恰好反转这四段的中间两端，则左边的两段都小于pivot，右边的两段则都大于等于pivot。所以，接下来分别在两段上递归调用mergeInPlace，即可。这整个过程其实非常像quicksort的过程。


```
举个例子：

1 5 10 15 2 8 12 16

from = 0, to = 8, mid = 5
经过第一段代码后：
from' = 1, to' = 7
经过第二段代码后：
first_cut = 2, second_cut = 6
经过第三段代码后，序列变为：
1 5 2 8 10 15 12 16
然后分别对[1 5 2 8] 和 [10 15 12 16]进行递归调用。
```

至此，in place的mergesort就完成了。但是我很难说服自己这仍然是mergesort，这更像是将merge的过程变成了quicksort。当然比起普通的那个归并排序而言，复杂度也上升了。merge过程本来是O($n$)的复杂度，现在变成了O($nlogn$)，从而整体的复杂度也从O($nlogn$)变成了O($nlog^2n$)

##Introsort

{% blockquote %}
Introsort or introspective sort is a hybrid sorting algorithm that provides both fast average performance and (asymptotically) optimal worst-case performance. It begins with quicksort and switches to heapsort when the recursion depth exceeds a level based on (the logarithm of) the number of elements being sorted. This combines the good parts of both algorithms, with practical performance comparable to quicksort on typical data sets and worst-case O($nlogn$) runtime due to the heap sort.
{% endblockquote %}

上面是Wikipedia上对introsort的一段解释。简单的说，introsort是quicksort和heapsort的结合，当递归深度超过$logn$的时候，就不在继续递归，而转而执行quicksort，从而达到最坏情况O($nlogn$)的时间复杂度。下面就来看一下org.apache.lucene.util.IntroSorter中的实现。

```
  void quicksort(int from, int to, int maxDepth) {
    if (to - from < THRESHOLD) {
      insertionSort(from, to);
      return;
    } else if (--maxDepth < 0) {
      //When the recursion depth reaches O(nlogn), stop recursion and sort with heapSort
      heapSort(from, to);
      return;
    }

    final int mid = (from + to) >>> 1;

    if (compare(from, mid) > 0) {
      swap(from, mid);
    }

    if (compare(mid, to - 1) > 0) {
      swap(mid, to - 1);
      if (compare(from, mid) > 0) {
        swap(from, mid);
      }
    }

    int left = from + 1;
    int right = to - 2;

    setPivot(mid);
    for (;;) {
      while (comparePivot(right) < 0) {
        --right;
      }

      while (left < right && comparePivot(left) >= 0) {
        ++left;
      }

      if (left < right) {
        swap(left, right);
        --right;
      } else {
        break;
      }
    }

    quicksort(from, left + 1, maxDepth);
    quicksort(left + 1, to, maxDepth);
  }
```

首先，请无视setPivot和comparePivot两个函数，因为IntroSorter是一个抽象类，所以其中没有数据成员储存pivot，故而将这个方法的具体实现交给了它的子类来完成。comparePivot(i)即是比较pivot和[i]的大小。我们可以看到在函数的一开始即判断了maxDepth是否已经到达$logn$，如果到达了则转而使用堆排序。其余部分的实现没有什么特别值得注意的地方，就是普通的quicksort的实现。不过这里用了很直观的实现方法，没有像有些实现中将pivot的位置换来换去，获得了更短的代码长度，但是却丧失了可读性。

综上，introsort似乎只是在quicksort的伤口处贴上了heapsort做的创可贴罢了，不过可以想到，quicksort的最坏情况出现的概率应该非常低，所以整体执行效率应该还是提升了的。Wikipedia上交代，c++的std::sort就是introsort，how astonishing it is!

##Timsort

{% blockquote %}
Timsort is a hybrid sorting algorithm, derived from merge sort and insertion sort, designed to perform well on many kinds of real-world data. It was invented by Tim Peters in 2002 for use in the Python programming language. The algorithm finds subsets of the data that are already ordered, and uses that knowledge to sort the remainder more efficiently. This is done by merging an identified subset, called a run, with existing runs until certain criteria are fulfilled. Timsort has been Python's standard sorting algorithm since version 2.3. It is also used to sort arrays of non-primitive type in Java SE 7, on the Android platform, and in GNU Octave
{% endblockquote %}

上面这段是Wikipedia上对Timsort的描述，从中我们可以知道Timsort是mergesort和insertionsort的结合。主要利用了原序列中已经有序的区间。而且python 2.3以后的标准排序算法和Java 7中非基本类型的排序算法都是用Timsort实现的。可见Timsort在工业界是很受追捧的，可是我竟然从来没有听过。。。汗

经过一个下午的研究，我对Timsort的理解大致如下。首先找出根据序列中的递增、递降的子序列，将递降的子序列反转，则得到了若干个已经有序的子串。此处其实是非严格递增和严格递降，因为该算法最终也是一个稳定排序算法。对于这些子串，根据子串的长度关系，两两归并。考虑长度关系，等价于控制mergesort中的递归深度。保证时间复杂度仍然是O($nlogn$)这个级别。

```
  public void sort(int from, int to) {
    checkRange(from, to);
    if (to - from <= 1) {
      return;
    }
    reset(from, to);
    do {
      ensureInvariants();
      pushRunLen(nextRun());
    } while (runEnd(0) < to);
    exhaustStack();
    assert runEnd(0) == to;
  }
```

Timsort中的辅助函数非常多，我们先看看上面这段整个排序的骨干代码。checkRange用来保证from < to。而reset则用于初始化一个子串栈，栈中的每个元素，为已经有序的一个子串的结束下标。ensureInvariants则用于合并栈中元素， 即归并这个过程。nextRun用于在原串中找到下一个有序子串。并且通过pushRunLen压栈。最后exhaustStack清栈，保证栈中仅存一个元素，即已经排序完成。下面我们分别看看这些函数的内容。

```
  void reset(int from, int to) {
    stackSize = 0;
    Arrays.fill(runEnds, 0);
    runEnds[0] = from;
    this.to = to;
    final int length = to - from;
    this.minRun = length <= THRESHOLD ? length : minRun(length);
  }
```

首先来看reset函数干了什么。1.初始化栈，2. 设定minRun的值，这里一个run就是一个有序子串的意思，而minRun则限定了一个run的最小长度，如果长度不足minRun，则会通过binarySort来将长度为minRun的子串排序。这里的binarySort，我认为就是插入排序中，通过二分来找到要插入的位置而已。Wikipedia中也说Timsort是mergesort和insertionsort的结合，而lucene这里将其命名为binarySort。

```
void ensureInvariants() {
	//runLen(i) returns the (stackSize - i - 1)th element
	//so runLen0 means the last element, runLen1 means the second to last element, same to runLen2
    while (stackSize > 1) {
      final int runLen0 = runLen(0);
      final int runLen1 = runLen(1);

      if (stackSize > 2) {
        final int runLen2 = runLen(2);

        if (runLen2 <= runLen1 + runLen0) {
          // merge the smaller of 0 and 2 with 1
          if (runLen2 < runLen0) {
            mergeAt(1);
          } else {
            mergeAt(0);
          }
          continue;
        }
      }

      if (runLen1 <= runLen0) {
        mergeAt(0);
        continue;
      }

      break;
    }
}
```

下面来看ensureInvariants，若栈中只有两个元素，若第一个的长度小于第二个的，则归并；弱栈中有超过两个元素，则考虑最后三个，将倒数第一个和倒数第三个中长度较小的那个和倒数第二个合并。直到栈中只有一个元素或两个元素。

```
void mergeAt(int n) {
    assert stackSize >= 2;
    merge(runBase(n + 1), runBase(n), runEnd(n));
    for (int j = n + 1; j > 0; --j) {
      setRunEnd(j, runEnd(j-1));
    }
    --stackSize;
  }

  void merge(int lo, int mid, int hi) {
    if (compare(mid - 1, mid) <= 0) {
      return;
    }
    //Same trick as in in place merge
    lo = upper2(lo, mid, mid);
    hi = lower2(mid, hi, mid - 1);

    if (hi - mid <= mid - lo && hi - mid <= maxTempSlots) {
      mergeHi(lo, mid, hi);
    } else if (mid - lo <= maxTempSlots) {
      mergeLo(lo, mid, hi);
    } else {
      mergeInPlace(lo, mid, hi);
    }
  }
```

下面来看看merge的过程，mergeAt(i)即是merge倒数第i个和倒数第i-1个元素。merge之后，再更新栈。
merge(lo, mid, hi)是将[lo, mid)和[mid, hi)的函数。我们看到这里用到了和mergeInPlace中一样的小优化。若有一部分的长度小于maxTempSlots，则使用长度为maxTempSlots的临时缓冲区来进行merge。否则进行mergeInPlace操作，这里的mergeInPlace就是本文阐述的第一个算法。

{% blockquote %}
NOTE</b>:There are a few differences with the original implementation:<ul>
<li>The extra amount of memory to perform merges is
configurable. This allows small merges to be very fast while large merges
will be performed in-place (slightly slower). You can make sure that the
fast merge routine will always be used by having <code>maxTempSlots</code>
equal to half of the length of the slice of data to sort.</li>
<li>Only the fast merge routine can gallop (the one that doesn't run
in-place) and it only gallops on the longest slice.</li>
</ul>
{% endblockquote %}

在org.apache.lucene.util.TimSorter的类注释中，有上面一段话，第二个bullet我们等会再说。我们先看第一个bullet，在这里我们用来归并的内存是可配的，而我们可以通过将其配置为整个序列长度的一半，来使得所有merge都可以快速的进行。

```
void mergeLo(int lo, int mid, int hi) {
    assert compare(lo, mid) > 0;
    int len1 = mid - lo;
    //copy [lo, lo+len1) to the temp storage
    save(lo, len1);
    //move [mid] to position lo. We can be sure that [mid] is the smallest element in this range, 
    //because of the optimistion trick performed in merge
    copy(mid, lo);
    int i = 0, j = mid + 1, dest = lo + 1;
    outer: for (;;) {
      //GALLOP
      for (int count = 0; count < MIN_GALLOP; ) {
        if (i >= len1 || j >= hi) {
          break outer;
        } else if (compareSaved(i, j) <= 0) {
          restore(i++, dest++);
          count = 0;
        } else {
          copy(j++, dest++);
          ++count;
        }
      }
      // galloping...
      int next = lowerSaved3(j, hi, i);
      for (; j < next; ++dest) {
        copy(j++, dest);
      }
      restore(i++, dest++);
    }
    //TODO: The jump out condition must meet with j >= hi, since the first half are strictly 
    //greater than the last half. Because lo and hi are obtained by search [mid].
    for (; i < len1; ++dest) {
      restore(i++, dest);
    }
    assert j == dest;
  }
```

由于mergeLo和mergeHi的原理是一样的，所以我们这里只针对mergeLo进行说明。首先将第一段复制到临时存储区，然后将第二段的开头元素置于整个序列的开头，这里我们可以确定这个元素是两段中最小的一个。然后就是两个指针，一个指向临时存储区，一个指向序列的后半段，从mid+1开始，进行归并。不过需要注意的一点是，这里有一个count，一旦从序列第二段，即较长的那一段移到整个序列前端的元素个数达到MIN_GALLOP时，就对此时临时存储区中正在处理的元素，通过二分查找它在第二段元素中的lower_bound，然后将lower_bound前面的元素全部移到序列前端。

这也就是org.apache.lucene.util.TimSorter的类注释中的第二个bullet。只有fast merge才有GALLOP机制，mergeInPlace没有这个机制。GALLOP在英文中的意思是飞快、飞速，在这里是一种优化手段。下面是一张关于GALLOP的示意图：

{% img /img/galloping_mode_timsort.svg.png 400 %}

##结语
至此三种见诸于教科书外的排序算法讲完。下表是Wikipedia上各种排序算法的时间及空间比较：

  Algorithm  | Timsort | Introsort | Mergesort | Quicksort | Insertion sort | Selection sort | Smoothsort
-----|-------|-------|-------|-------|-------|-------|-------  
Best Case | O($n$) |  | O($nlogn$) | O($nlogn$) | O($n$) | O($n^2$) | O($n$)
Average Case | O($nlogn$) | O($nlogn$) | O($nlogn$) | O($nlogn$) | O($n^2$) | O($n^2$) | O($nlogn$)
Worst Case | O($nlogn$) | O($nlogn$) | O($nlogn$) | O($n^2$) | O($n^2$) | O($n^2$) | O($nlogn$)
Space complexity | O($n$) || O($n$) | O($n$) | O($1$) | O($1$) | O($1$)

